{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b649bf",
   "metadata": {},
   "source": [
    "1. Data Collection: Gather historical cryptocurrency price, volume, and liquidity-related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d8e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "df_16 = pd.read_csv(\"coin_gecko_2022-03-16.csv\")\n",
    "df_17 = pd.read_csv(\"coin_gecko_2022-03-17.csv\")\n",
    "\n",
    "# Display dataset structure\n",
    "print(\"Columns in dataset:\", df_16.columns)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nSummary of 16th March dataset:\")\n",
    "print(df_16.describe())\n",
    "\n",
    "print(\"\\nSummary of 17th March dataset:\")\n",
    "print(df_17.describe())\n",
    "\n",
    "# Merge both datasets on 'symbol' for comparative analysis\n",
    "merged_df = df_16.merge(df_17, on=\"symbol\", suffixes=(\"_16\", \"_17\"))\n",
    "\n",
    "# Compute price, volume, and market cap changes\n",
    "merged_df[\"price_change\"] = merged_df[\"price_17\"] - merged_df[\"price_16\"]\n",
    "merged_df[\"volume_change\"] = merged_df[\"24h_volume_17\"] - merged_df[\"24h_volume_16\"]\n",
    "merged_df[\"mkt_cap_change\"] = merged_df[\"mkt_cap_17\"] - merged_df[\"mkt_cap_16\"]\n",
    "\n",
    "# Top gainers and losers based on price change\n",
    "top_gainers = merged_df.nlargest(5, \"price_change\")[[\"coin_17\", \"price_change\"]]\n",
    "top_losers = merged_df.nsmallest(5, \"price_change\")[[\"coin_17\", \"price_change\"]]\n",
    "\n",
    "print(\"\\nTop 5 Gainers:\")\n",
    "print(top_gainers)\n",
    "\n",
    "print(\"\\nTop 5 Losers:\")\n",
    "print(top_losers)\n",
    "\n",
    "# Save processed data to CSV\n",
    "merged_df.to_csv(\"crypto_comparison.csv\", index=False)\n",
    "print(\"\\nProcessed dataset saved as crypto_comparison.csv\")\n",
    "\n",
    "# Visualization (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(merged_df[\"price_change\"], bins=30, edgecolor=\"black\")\n",
    "plt.title(\"Price Change Distribution\")\n",
    "plt.xlabel(\"Price Change\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0e441",
   "metadata": {},
   "source": [
    "2. Data Preprocessing: Handle missing values, clean data, and normalize numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0937ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load datasets\n",
    "df_16 = pd.read_csv(\"coin_gecko_2022-03-16.csv\")\n",
    "df_17 = pd.read_csv(\"coin_gecko_2022-03-17.csv\")\n",
    "\n",
    "# Identify missing values\n",
    "print(\"Missing values:\\n\", df_16.isnull().sum())\n",
    "\n",
    "# Handle missing values - fill missing numerical data with median values\n",
    "num_cols = [\"price\", \"1h\", \"24h\", \"7d\", \"24h_volume\", \"mkt_cap\"]\n",
    "df_16[num_cols] = df_16[num_cols].fillna(df_16[num_cols].median())\n",
    "df_17[num_cols] = df_17[num_cols].fillna(df_17[num_cols].median())\n",
    "\n",
    "# Drop duplicates (if any)\n",
    "df_16 = df_16.drop_duplicates()\n",
    "df_17 = df_17.drop_duplicates()\n",
    "\n",
    "# Normalize numerical features using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "df_16[num_cols] = scaler.fit_transform(df_16[num_cols])\n",
    "df_17[num_cols] = scaler.transform(df_17[num_cols])\n",
    "\n",
    "# Save cleaned dataset\n",
    "df_16.to_csv(\"cleaned_crypto_16.csv\", index=False)\n",
    "df_17.to_csv(\"cleaned_crypto_17.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaning and normalization complete! Processed files saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944bb61",
   "metadata": {},
   "source": [
    "3. Exploratory Data Analysis (EDA): Analyze data patterns, trends, and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01323341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Inspect datasets\n",
    "print(\"\\nDataset Structure:\")\n",
    "print(\"March 16 Data:\\n\", df_16.info())\n",
    "print(\"\\nMarch 17 Data:\\n\", df_17.info())\n",
    "\n",
    "# Handle missing values - fill numerical columns with median\n",
    "num_cols = [\"price\", \"1h\", \"24h\", \"7d\", \"24h_volume\", \"mkt_cap\"]\n",
    "df_16[num_cols] = df_16[num_cols].fillna(df_16[num_cols].median())\n",
    "df_17[num_cols] = df_17[num_cols].fillna(df_17[num_cols].median())\n",
    "\n",
    "# Merge both datasets on 'symbol' for comparative analysis\n",
    "merged_df = df_16.merge(df_17, on=\"symbol\", suffixes=(\"_16\", \"_17\"))\n",
    "\n",
    "# Compute changes in price, volume, and market cap\n",
    "merged_df[\"price_change\"] = merged_df[\"price_17\"] - merged_df[\"price_16\"]\n",
    "merged_df[\"volume_change\"] = merged_df[\"24h_volume_17\"] - merged_df[\"24h_volume_16\"]\n",
    "merged_df[\"mkt_cap_change\"] = merged_df[\"mkt_cap_17\"] - merged_df[\"mkt_cap_16\"]\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = merged_df[[\"price_16\", \"price_17\", \"24h_volume_16\", \"24h_volume_17\", \"mkt_cap_16\", \"mkt_cap_17\"]].corr()\n",
    "print(\"\\nCorrelation Matrix:\\n\", corr_matrix)\n",
    "\n",
    "# Visualization - Price Change Distribution\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(merged_df[\"price_change\"], bins=30, edgecolor=\"black\")\n",
    "plt.title(\"Price Change Distribution\")\n",
    "plt.xlabel(\"Price Change\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization - Market Cap vs. Volume Change\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(data=merged_df, x=\"mkt_cap_change\", y=\"volume_change\", hue=\"symbol\")\n",
    "plt.title(\"Market Cap vs Volume Change\")\n",
    "plt.xlabel(\"Market Cap Change (USD)\")\n",
    "plt.ylabel(\"Trading Volume Change (USD)\")\n",
    "plt.show()\n",
    "\n",
    "# Save processed dataset\n",
    "merged_df.to_csv(\"crypto_comparison.csv\", index=False)\n",
    "print(\"\\nProcessed dataset saved as crypto_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46848e6",
   "metadata": {},
   "source": [
    "4. Feature Engineering: Create relevant liquidity-related features such as moving averages, volatility, and liquidity ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0320b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets on 'coin' to compare changes\n",
    "df = df_16.merge(df_17, on=\"coin\", suffixes=(\"_16\", \"_17\"))\n",
    "\n",
    "# Convert percentages to decimals\n",
    "for col in [\"1h_16\", \"24h_16\", \"7d_16\", \"1h_17\", \"24h_17\", \"7d_17\"]:\n",
    "    df[col] = df[col] / 100.0\n",
    "\n",
    "# --- Liquidity Ratios ---\n",
    "df[\"turnover_ratio_16\"] = df[\"24h_volume_16\"] / df[\"mkt_cap_16\"]\n",
    "df[\"turnover_ratio_17\"] = df[\"24h_volume_17\"] / df[\"mkt_cap_17\"]\n",
    "\n",
    "df[\"liquidity_score_16\"] = (df[\"24h_volume_16\"] * df[\"price_16\"]) / df[\"mkt_cap_16\"]\n",
    "df[\"liquidity_score_17\"] = (df[\"24h_volume_17\"] * df[\"price_17\"]) / df[\"mkt_cap_17\"]\n",
    "\n",
    "# --- Moving Averages ---\n",
    "# Simulating rolling window (7d, 30d) using available 2-day data\n",
    "df[\"price_ma_7d\"] = (df[\"price_16\"] + df[\"price_17\"]) / 2\n",
    "df[\"volume_ma_7d\"] = (df[\"24h_volume_16\"] + df[\"24h_volume_17\"]) / 2\n",
    "\n",
    "# --- Volatility Measures ---\n",
    "df[\"volatility_1h\"] = np.abs(df[\"1h_17\"] - df[\"1h_16\"])\n",
    "df[\"volatility_24h\"] = np.abs(df[\"24h_17\"] - df[\"24h_16\"])\n",
    "df[\"volatility_7d\"] = np.abs(df[\"7d_17\"] - df[\"7d_16\"])\n",
    "\n",
    "# --- Price Momentum ---\n",
    "df[\"momentum_24h\"] = df[\"price_17\"] - df[\"price_16\"]\n",
    "df[\"momentum_7d\"] = df[\"price_17\"] - df[\"price_ma_7d\"]\n",
    "\n",
    "# --- Relative Market Strength (RMS) ---\n",
    "df[\"RMS\"] = (df[\"price_17\"] - df[\"price_ma_7d\"]) / df[\"volatility_7d\"]\n",
    "\n",
    "# Save the engineered dataset\n",
    "df.to_csv(\"crypto_liquidity_features.csv\", index=False)\n",
    "\n",
    "print(\"Feature Engineering Complete! Results saved in 'crypto_liquidity_features.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688eaa8",
   "metadata": {},
   "source": [
    "5. Model Selection: Choose appropriate machine learning models such as time-series forecasting, regression, or deep learning approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed820b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load datasets\n",
    "df_16 = pd.read_csv(\"coin_gecko_2022-03-16.csv\")\n",
    "df_17 = pd.read_csv(\"coin_gecko_2022-03-17.csv\")\n",
    "\n",
    "# Combine datasets for time-series analysis\n",
    "df = pd.concat([df_16, df_17])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Sort data by date\n",
    "df = df.sort_index()\n",
    "\n",
    "# Select top cryptocurrency for forecasting (Bitcoin example)\n",
    "btc_df = df[df['coin'] == 'Bitcoin'][['price', '24h_volume', 'mkt_cap']]\n",
    "\n",
    "# Create moving averages\n",
    "btc_df['ma_7d'] = btc_df['price'].rolling(window=7).mean()\n",
    "btc_df['ma_30d'] = btc_df['price'].rolling(window=30).mean()\n",
    "\n",
    "# Calculate volatility\n",
    "btc_df['volatility_7d'] = btc_df['price'].rolling(window=7).std()\n",
    "\n",
    "# Liquidity ratio\n",
    "btc_df['liquidity_ratio'] = btc_df['24h_volume'] / btc_df['mkt_cap']\n",
    "\n",
    "# Remove NaN values\n",
    "btc_df.dropna(inplace=True)\n",
    "\n",
    "# Plot price trend\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(btc_df.index, btc_df['price'], label=\"Price\")\n",
    "plt.plot(btc_df.index, btc_df['ma_7d'], label=\"7-Day MA\", linestyle=\"--\")\n",
    "plt.plot(btc_df.index, btc_df['ma_30d'], label=\"30-Day MA\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"Bitcoin Price Trend\")\n",
    "plt.show()\n",
    "\n",
    "# --- ARIMA MODEL ---\n",
    "model_arima = ARIMA(btc_df['price'], order=(5,1,0))\n",
    "arima_result = model_arima.fit()\n",
    "btc_df['arima_forecast'] = arima_result.predict()\n",
    "\n",
    "# --- SARIMA MODEL (Seasonality Consideration) ---\n",
    "sarima_model = SARIMAX(btc_df['price'], order=(1,1,1), seasonal_order=(1,1,1,7))\n",
    "sarima_result = sarima_model.fit()\n",
    "btc_df['sarima_forecast'] = sarima_result.predict()\n",
    "\n",
    "# --- LSTM MODEL ---\n",
    "data = btc_df[['price']].values\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# Prepare LSTM sequences\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train)\n",
    "X_test, y_test = create_sequences(test)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(50),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train LSTM Model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=16)\n",
    "\n",
    "# Predict\n",
    "pred_lstm = lstm_model.predict(X_test)\n",
    "\n",
    "# Plot forecast results\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(btc_df.index[-len(pred_lstm):], pred_lstm, label=\"LSTM Forecast\")\n",
    "plt.plot(btc_df.index, btc_df['arima_forecast'], label=\"ARIMA Forecast\", linestyle=\"--\")\n",
    "plt.plot(btc_df.index, btc_df['sarima_forecast'], label=\"SARIMA Forecast\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"Bitcoin Liquidity Forecast\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a53c8b",
   "metadata": {},
   "source": [
    "6. Model Training: Train the selected model using the processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_csv(\"crypto_liquidity_features.csv\")\n",
    "\n",
    "# Convert date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Sort data by date\n",
    "df = df.sort_index()\n",
    "\n",
    "# Select top cryptocurrency for forecasting (Example: Bitcoin)\n",
    "btc_df = df[df['coin'] == 'Bitcoin'][['price', '24h_volume', 'liquidity_ratio']]\n",
    "\n",
    "# --- ARIMA Model for Price Forecasting ---\n",
    "model_arima = ARIMA(btc_df['price'], order=(5,1,0))\n",
    "arima_result = model_arima.fit()\n",
    "btc_df['arima_forecast'] = arima_result.predict()\n",
    "\n",
    "# --- SARIMA Model (Seasonality Consideration) ---\n",
    "sarima_model = SARIMAX(btc_df['price'], order=(1,1,1), seasonal_order=(1,1,1,7))\n",
    "sarima_result = sarima_model.fit()\n",
    "btc_df['sarima_forecast'] = sarima_result.predict()\n",
    "\n",
    "# --- LSTM Model ---\n",
    "data = btc_df[['price']].values\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# Prepare LSTM sequences\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(train)\n",
    "X_test, y_test = create_sequences(test)\n",
    "\n",
    "# Define LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train LSTM Model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=16)\n",
    "\n",
    "# Predict using LSTM\n",
    "pred_lstm = lstm_model.predict(X_test)\n",
    "\n",
    "# --- Plot Forecast Results ---\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(btc_df.index[-len(pred_lstm):], pred_lstm, label=\"LSTM Forecast\")\n",
    "plt.plot(btc_df.index, btc_df['arima_forecast'], label=\"ARIMA Forecast\", linestyle=\"--\")\n",
    "plt.plot(btc_df.index, btc_df['sarima_forecast'], label=\"SARIMA Forecast\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"Bitcoin Liquidity Forecast\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad407170",
   "metadata": {},
   "source": [
    "7. Model Evaluation: Assess model performance using metrics such as RMSE, MAE, and R² score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the processed dataset containing actual & forecasted values\n",
    "df = pd.read_csv(\"crypto_liquidity_features.csv\")\n",
    "\n",
    "# Select Bitcoin data for evaluation (adjust for your target cryptocurrency)\n",
    "# Ensure the required columns exist in the dataframe\n",
    "if 'arima_forecast' not in df.columns or 'sarima_forecast' not in df.columns:\n",
    "    # Generate ARIMA and SARIMA forecasts if not already present\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "    # Filter Bitcoin data\n",
    "    btc_df = df[df['coin'] == 'Bitcoin']\n",
    "\n",
    "    # Generate ARIMA forecast\n",
    "    arima_model = ARIMA(btc_df['price'], order=(5, 1, 0))\n",
    "    arima_result = arima_model.fit()\n",
    "    df.loc[df['coin'] == 'Bitcoin', 'arima_forecast'] = arima_result.predict()\n",
    "\n",
    "    # Generate SARIMA forecast\n",
    "    sarima_model = SARIMAX(btc_df['price'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 7))\n",
    "    sarima_result = sarima_model.fit()\n",
    "    df.loc[df['coin'] == 'Bitcoin', 'sarima_forecast'] = sarima_result.predict()\n",
    "\n",
    "# Filter Bitcoin data with forecasts\n",
    "btc_df = df[df['coin'] == 'Bitcoin'][['price', 'arima_forecast', 'sarima_forecast']]\n",
    "\n",
    "# Ensure no missing values\n",
    "btc_df.dropna(inplace=True)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Performance of {model_name}:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Evaluate ARIMA model\n",
    "evaluate_model(btc_df['price'], btc_df['arima_forecast'], \"ARIMA\")\n",
    "\n",
    "# Evaluate SARIMA model\n",
    "evaluate_model(btc_df['price'], btc_df['sarima_forecast'], \"SARIMA\")\n",
    "\n",
    "# If using an LSTM model, load predictions (assumed saved in CSV)\n",
    "try:\n",
    "    lstm_preds = pd.read_csv(\"lstm_forecasts.csv\")\n",
    "    evaluate_model(btc_df['price'][-len(lstm_preds):], lstm_preds['lstm_forecast'], \"LSTM\")\n",
    "except FileNotFoundError:\n",
    "    print(\"LSTM forecast file not found, skipping LSTM evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cb6e9",
   "metadata": {},
   "source": [
    "8. Hyperparameter Tuning: Optimize model parameters for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acddafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import keras_tuner\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"crypto_liquidity_features.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Select Bitcoin data (modify for other assets)\n",
    "btc_df = df[df['coin'] == 'Bitcoin']['price']\n",
    "\n",
    "# --- ARIMA Hyperparameter Tuning ---\n",
    "p = d = q = range(0, 4)\n",
    "pdq_combinations = list(itertools.product(p, d, q))\n",
    "\n",
    "best_aic = float(\"inf\")\n",
    "best_order = None\n",
    "\n",
    "for order in pdq_combinations:\n",
    "    try:\n",
    "        model = ARIMA(btc_df, order=order)\n",
    "        results = model.fit()\n",
    "        if results.aic < best_aic:\n",
    "            best_aic = results.aic\n",
    "            best_order = order\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Best ARIMA Order: {best_order} with AIC: {best_aic}\")\n",
    "\n",
    "# --- SARIMA Hyperparameter Tuning ---\n",
    "P = D = Q = range(0, 3)\n",
    "seasonal_pdq = list(itertools.product(P, D, Q, [7]))\n",
    "\n",
    "best_mse = float(\"inf\")\n",
    "best_seasonal_order = None\n",
    "\n",
    "for seasonal_order in seasonal_pdq:\n",
    "    try:\n",
    "        model = SARIMAX(btc_df, order=(1,1,1), seasonal_order=seasonal_order)\n",
    "        results = model.fit()\n",
    "        mse = np.mean(np.square(results.resid))\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_seasonal_order = seasonal_order\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"Best SARIMA Order: {best_seasonal_order} with MSE: {best_mse}\")\n",
    "\n",
    "# --- LSTM Hyperparameter Tuning ---\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=50, max_value=150, step=50), return_sequences=True, input_shape=(5, 1)))\n",
    "    model.add(LSTM(units=hp.Int('units', min_value=50, max_value=150, step=50)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_lstm_model,\n",
    "    objective=\"loss\",\n",
    "    max_trials=5\n",
    ")\n",
    "\n",
    "# Prepare LSTM data\n",
    "data = btc_df.values.reshape(-1, 1)\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "X_train, y_train = [], []\n",
    "for i in range(len(train) - 5):\n",
    "    X_train.append(train[i:i+5])\n",
    "    y_train.append(train[i+5])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=10, batch_size=16)\n",
    "\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best LSTM Hyperparameters: {best_hyperparameters.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ca3a2",
   "metadata": {},
   "source": [
    "9. Model Testing & Validation: Test the model on unseen data and analyze predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load processed dataset\n",
    "df = pd.read_csv(\"crypto_liquidity_features.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Select Bitcoin data for testing (Modify for other cryptocurrencies)\n",
    "btc_df = df[df['coin'] == 'Bitcoin'][['price']]\n",
    "\n",
    "# Split into training & test sets (80% training, 20% test)\n",
    "train_size = int(len(btc_df) * 0.8)\n",
    "train, test = btc_df[:train_size], btc_df[train_size:]\n",
    "\n",
    "# --- ARIMA Model Testing ---\n",
    "arima_model = ARIMA(train, order=(5,1,0))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "# Predict ARIMA on test set\n",
    "arima_preds = arima_result.forecast(steps=len(test))\n",
    "\n",
    "# --- SARIMA Model Testing ---\n",
    "sarima_model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,7))\n",
    "sarima_result = sarima_model.fit()\n",
    "\n",
    "# Predict SARIMA on test set\n",
    "sarima_preds = sarima_result.forecast(steps=len(test))\n",
    "\n",
    "# --- LSTM Model Testing ---\n",
    "data = train.values\n",
    "seq_length = 5\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_sequences(data)\n",
    "X_test, y_test = create_sequences(test.values)\n",
    "\n",
    "# Define LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train LSTM Model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=16)\n",
    "\n",
    "# Predict using LSTM\n",
    "lstm_preds = lstm_model.predict(X_test)\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} Performance:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R² Score: {r2:.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "evaluate_model(test, arima_preds, \"ARIMA\")\n",
    "evaluate_model(test, sarima_preds, \"SARIMA\")\n",
    "evaluate_model(y_test, lstm_preds.flatten(), \"LSTM\")\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(test.index, test, label=\"Actual Prices\", color=\"black\")\n",
    "plt.plot(test.index, arima_preds, label=\"ARIMA Predictions\", linestyle=\"--\", color=\"blue\")\n",
    "plt.plot(test.index, sarima_preds, label=\"SARIMA Predictions\", linestyle=\"--\", color=\"green\")\n",
    "plt.plot(test.index[-len(lstm_preds):], lstm_preds.flatten(), label=\"LSTM Predictions\", linestyle=\"--\", color=\"red\")\n",
    "plt.legend()\n",
    "plt.title(\"Bitcoin Liquidity Forecast vs. Actual Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad750ed",
   "metadata": {},
   "source": [
    "10. Local Deployment: Deploy the trained model locally using Flask or Streamlit for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load trained model and dataset\n",
    "df = pd.read_csv(\"crypto_liquidity_features.csv\")\n",
    "btc_df = df[df['coin'] == 'Bitcoin']['price']\n",
    "\n",
    "# Train ARIMA model\n",
    "model = ARIMA(btc_df, order=(5,1,0))\n",
    "result = model.fit()\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    steps = data.get(\"steps\", 5)\n",
    "\n",
    "    forecast = result.forecast(steps=steps).tolist()\n",
    "\n",
    "    return jsonify({\"prediction\": forecast})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
